{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76888230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29330, 7)\n",
      "         Date   Time  Code Value  patient_id             datetime record_type\n",
      "0  04-21-1991   9:09    58   100           1  1991-04-21 09:09:00  Electronic\n",
      "1  04-21-1991   9:09    33     9           1  1991-04-21 09:09:00  Electronic\n",
      "2  04-21-1991   9:09    34    13           1  1991-04-21 09:09:00  Electronic\n",
      "3  04-21-1991  17:08    62   119           1  1991-04-21 17:08:00  Electronic\n",
      "4  04-21-1991  17:08    33     7           1  1991-04-21 17:08:00  Electronic\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/Users/akki/Desktop/AKKI/college/AI in Healthcare/Project/Blood Glucose Prediction/Diabetes-Data/patient_data.csv\")\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddfc3835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Value'] = pd.to_numeric(df['Value'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68f756fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_codes = [58, 60, 62]\n",
    "bg_df = df[df['Code'].isin(bg_codes)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dafc377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark event type columns\n",
    "df['is_insulin'] = df['Code'].isin([33, 34, 35]).astype(int)\n",
    "df['is_meal']    = df['Code'].isin([66, 67, 68]).astype(int)\n",
    "df['is_exercise']= df['Code'].isin([69, 70, 71]).astype(int)\n",
    "\n",
    "# For each datetime, aggregate\n",
    "agg_df = df.groupby(['patient_id','datetime']).agg({\n",
    "    'Value':'mean',\n",
    "    'is_insulin':'max',\n",
    "    'is_meal':'max',\n",
    "    'is_exercise':'max'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e329b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = agg_df.sort_values(['patient_id','datetime'])\n",
    "agg_df['prev_bg'] = agg_df.groupby('patient_id')['Value'].shift(1)\n",
    "agg_df['prev_insulin'] = agg_df.groupby('patient_id')['is_insulin'].shift(1)\n",
    "agg_df['prev_meal'] = agg_df.groupby('patient_id')['is_meal'].shift(1)\n",
    "agg_df['prev_exercise'] = agg_df.groupby('patient_id')['is_exercise'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac3e256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df['target_bg'] = agg_df.groupby('patient_id')['Value'].shift(-1)\n",
    "model_df = agg_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96887c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 74.51928788746062\n",
      "RMSE: 105.91294400865351\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "X = model_df[['Value','prev_bg','prev_insulin','prev_meal','prev_exercise']]\n",
    "y = model_df['target_bg']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "print(\"MAE:\", mean_absolute_error(y_test, preds))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c6d97d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1: MAE=52.08, RMSE=64.84\n",
      "Patient 2: MAE=32.79, RMSE=41.60\n",
      "Patient 3: MAE=78.61, RMSE=100.38\n",
      "Patient 4: MAE=79.09, RMSE=103.67\n",
      "Patient 5: MAE=85.04, RMSE=103.71\n",
      "Patient 6: MAE=45.99, RMSE=49.69\n",
      "Patient 7: MAE=38.08, RMSE=50.92\n",
      "Patient 8: MAE=99.21, RMSE=116.74\n",
      "Patient 9: MAE=71.00, RMSE=105.78\n",
      "Patient 10: MAE=58.28, RMSE=79.12\n",
      "Patient 11: MAE=37.62, RMSE=63.60\n",
      "Patient 12: MAE=60.35, RMSE=86.57\n",
      "Patient 13: MAE=66.19, RMSE=99.46\n",
      "Patient 14: MAE=52.81, RMSE=92.24\n",
      "Patient 15: MAE=52.14, RMSE=74.13\n",
      "Patient 16: MAE=60.39, RMSE=99.03\n",
      "Patient 17: MAE=65.49, RMSE=86.82\n",
      "Patient 18: MAE=54.39, RMSE=75.96\n",
      "Patient 19: MAE=72.14, RMSE=108.97\n",
      "Patient 20: MAE=41.67, RMSE=48.61\n",
      "Patient 21: MAE=64.70, RMSE=87.10\n",
      "Patient 22: MAE=56.37, RMSE=80.59\n",
      "Patient 23: MAE=53.96, RMSE=87.07\n",
      "Patient 24: MAE=60.34, RMSE=86.64\n",
      "Patient 25: MAE=80.45, RMSE=100.50\n",
      "Patient 26: MAE=45.73, RMSE=55.98\n",
      "Patient 27: MAE=30.84, RMSE=42.12\n",
      "Patient 28: MAE=30.86, RMSE=42.45\n",
      "Patient 29: MAE=35.58, RMSE=46.28\n",
      "Patient 30: MAE=28.98, RMSE=40.03\n",
      "Patient 31: MAE=31.89, RMSE=48.20\n",
      "Patient 32: MAE=52.89, RMSE=73.40\n",
      "Patient 33: MAE=55.55, RMSE=79.58\n",
      "Patient 34: MAE=46.41, RMSE=64.72\n",
      "Patient 35: MAE=38.83, RMSE=55.95\n",
      "Patient 36: MAE=61.39, RMSE=82.85\n",
      "Patient 37: MAE=42.86, RMSE=68.43\n",
      "Patient 38: MAE=47.89, RMSE=76.92\n",
      "Patient 39: MAE=26.35, RMSE=44.25\n",
      "Patient 40: MAE=29.49, RMSE=42.39\n",
      "Patient 41: MAE=43.43, RMSE=51.35\n",
      "Patient 42: MAE=38.84, RMSE=46.40\n",
      "Patient 43: MAE=74.69, RMSE=117.81\n",
      "Patient 44: MAE=66.86, RMSE=98.29\n",
      "Patient 45: MAE=61.86, RMSE=99.70\n",
      "Patient 46: MAE=65.35, RMSE=99.38\n",
      "Patient 47: MAE=41.75, RMSE=71.93\n",
      "Patient 48: MAE=53.14, RMSE=75.09\n",
      "Patient 49: MAE=30.15, RMSE=36.82\n",
      "Patient 50: MAE=29.68, RMSE=37.34\n",
      "Patient 51: MAE=48.25, RMSE=64.03\n",
      "Patient 52: MAE=94.84, RMSE=130.90\n",
      "Patient 53: MAE=57.52, RMSE=83.27\n",
      "Patient 54: MAE=44.64, RMSE=59.61\n",
      "Patient 55: MAE=26.45, RMSE=37.45\n",
      "Patient 56: MAE=66.00, RMSE=85.22\n",
      "Patient 57: MAE=135.29, RMSE=160.00\n",
      "Patient 58: MAE=68.66, RMSE=107.58\n",
      "Patient 59: MAE=52.65, RMSE=90.91\n",
      "Patient 60: MAE=50.81, RMSE=83.93\n",
      "Patient 61: MAE=81.03, RMSE=119.34\n",
      "Patient 62: MAE=67.54, RMSE=100.95\n",
      "Patient 63: MAE=56.47, RMSE=88.46\n",
      "Patient 64: MAE=52.32, RMSE=68.21\n",
      "Patient 65: MAE=68.31, RMSE=90.96\n",
      "Patient 66: MAE=41.78, RMSE=53.83\n",
      "Patient 67: MAE=76.09, RMSE=107.29\n",
      "Patient 68: MAE=34.43, RMSE=43.39\n",
      "Patient 69: MAE=102.68, RMSE=121.48\n",
      "Patient 70: MAE=59.76, RMSE=74.48\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "patient_models = {}\n",
    "results = {}\n",
    "\n",
    "for pid, pdf in agg_df.groupby(\"patient_id\"):\n",
    "    # Drop rows with missing features\n",
    "    pdf = pdf.dropna(subset=[\"Value\", \"prev_bg\"])\n",
    "    \n",
    "    if len(pdf) < 50:  # skip very small datasets\n",
    "        continue\n",
    "    \n",
    "    X = pdf[[\"prev_bg\", 'prev_insulin','prev_meal','prev_exercise']]\n",
    "    y = pdf[\"Value\"]\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    \n",
    "    # Model\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    patient_models[pid] = model\n",
    "    results[pid] = {\"MAE\": mae, \"RMSE\": rmse}\n",
    "\n",
    "# Show results\n",
    "for pid, metrics in results.items():\n",
    "    print(f\"Patient {pid}: MAE={metrics['MAE']:.2f}, RMSE={metrics['RMSE']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad7f9824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# 1. Create sequence dataset\n",
    "class BGDataset(Dataset):\n",
    "    def __init__(self, df, seq_len=5):\n",
    "        self.seq_len = seq_len\n",
    "        self.features = df[[\"Value\", \"is_insulin\", \"is_meal\", \"is_exercise\"]].values\n",
    "        self.targets = df[\"Value\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.features[idx:idx+self.seq_len]\n",
    "        y = self.targets[idx+self.seq_len]\n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# 2. LSTM Model\n",
    "class BGLSTM(nn.Module):\n",
    "    def __init__(self, input_size=4, hidden_size=64, num_layers=2):\n",
    "        super(BGLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # last time step\n",
    "        return out.squeeze()\n",
    "\n",
    "# 3. Train function\n",
    "def train_lstm(df, seq_len=5, epochs=200, lr=0.001):\n",
    "    dataset = BGDataset(df, seq_len)\n",
    "    loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = BGLSTM()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for X, y in loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X)\n",
    "            loss = criterion(preds, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss={total_loss/len(loader):.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24aecdba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Code</th>\n",
       "      <th>Value</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>record_type</th>\n",
       "      <th>is_insulin</th>\n",
       "      <th>is_meal</th>\n",
       "      <th>is_exercise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04-21-1991</td>\n",
       "      <td>9:09</td>\n",
       "      <td>58</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1991-04-21 09:09:00</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04-21-1991</td>\n",
       "      <td>9:09</td>\n",
       "      <td>33</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1991-04-21 09:09:00</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04-21-1991</td>\n",
       "      <td>9:09</td>\n",
       "      <td>34</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1991-04-21 09:09:00</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04-21-1991</td>\n",
       "      <td>17:08</td>\n",
       "      <td>62</td>\n",
       "      <td>119.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1991-04-21 17:08:00</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04-21-1991</td>\n",
       "      <td>17:08</td>\n",
       "      <td>33</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1991-04-21 17:08:00</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29325</th>\n",
       "      <td>05-09-1989</td>\n",
       "      <td>08:00</td>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1989-05-09 08:00:00</td>\n",
       "      <td>Paper</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29326</th>\n",
       "      <td>05-09-1989</td>\n",
       "      <td>08:00</td>\n",
       "      <td>34</td>\n",
       "      <td>7.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1989-05-09 08:00:00</td>\n",
       "      <td>Paper</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29327</th>\n",
       "      <td>05-10-1989</td>\n",
       "      <td>08:00</td>\n",
       "      <td>34</td>\n",
       "      <td>7.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1989-05-10 08:00:00</td>\n",
       "      <td>Paper</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29328</th>\n",
       "      <td>05-11-1989</td>\n",
       "      <td>08:00</td>\n",
       "      <td>34</td>\n",
       "      <td>7.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1989-05-11 08:00:00</td>\n",
       "      <td>Paper</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29329</th>\n",
       "      <td>05-12-1989</td>\n",
       "      <td>08:00</td>\n",
       "      <td>34</td>\n",
       "      <td>7.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1989-05-12 08:00:00</td>\n",
       "      <td>Paper</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29330 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date   Time  Code  Value  patient_id             datetime  \\\n",
       "0      04-21-1991   9:09    58  100.0           1  1991-04-21 09:09:00   \n",
       "1      04-21-1991   9:09    33    9.0           1  1991-04-21 09:09:00   \n",
       "2      04-21-1991   9:09    34   13.0           1  1991-04-21 09:09:00   \n",
       "3      04-21-1991  17:08    62  119.0           1  1991-04-21 17:08:00   \n",
       "4      04-21-1991  17:08    33    7.0           1  1991-04-21 17:08:00   \n",
       "...           ...    ...   ...    ...         ...                  ...   \n",
       "29325  05-09-1989  08:00    33    1.0          70  1989-05-09 08:00:00   \n",
       "29326  05-09-1989  08:00    34    7.0          70  1989-05-09 08:00:00   \n",
       "29327  05-10-1989  08:00    34    7.0          70  1989-05-10 08:00:00   \n",
       "29328  05-11-1989  08:00    34    7.0          70  1989-05-11 08:00:00   \n",
       "29329  05-12-1989  08:00    34    7.0          70  1989-05-12 08:00:00   \n",
       "\n",
       "      record_type  is_insulin  is_meal  is_exercise  \n",
       "0      Electronic           0        0            0  \n",
       "1      Electronic           1        0            0  \n",
       "2      Electronic           1        0            0  \n",
       "3      Electronic           0        0            0  \n",
       "4      Electronic           1        0            0  \n",
       "...           ...         ...      ...          ...  \n",
       "29325       Paper           1        0            0  \n",
       "29326       Paper           1        0            0  \n",
       "29327       Paper           1        0            0  \n",
       "29328       Paper           1        0            0  \n",
       "29329       Paper           1        0            0  \n",
       "\n",
       "[29330 rows x 10 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955a66cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# 1. Create sequence dataset\n",
    "class BGDataset(Dataset):\n",
    "    def __init__(self, df, seq_len=5):\n",
    "        self.seq_len = seq_len\n",
    "        self.features = df[[\"Value\", \"is_insulin\", \"is_meal\", \"is_exercise\"]].values\n",
    "        self.targets = df[\"Value\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.features[idx:idx+self.seq_len]\n",
    "        y = self.targets[idx+self.seq_len]\n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# 2. LSTM Model\n",
    "class BGLSTM(nn.Module):\n",
    "    def __init__(self, input_size=4, hidden_size=64, num_layers=2):\n",
    "        super(BGLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # last time step\n",
    "        return out.squeeze()\n",
    "\n",
    "# 3. Train function with validation\n",
    "def train_lstm(df, seq_len=5, epochs=200, lr=0.001):\n",
    "    # Split into train and validation (80/20 chronologically)\n",
    "    train_size = int(0.8 * len(df))\n",
    "    train_df = df.iloc[:train_size]\n",
    "    val_df = df.iloc[train_size:]\n",
    "\n",
    "    train_loader = DataLoader(BGDataset(train_df, seq_len), batch_size=32, shuffle=False)\n",
    "    val_loader = DataLoader(BGDataset(val_df, seq_len), batch_size=32, shuffle=False)\n",
    "\n",
    "    model = BGLSTM()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # ---- Training ----\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for X, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X)\n",
    "            loss = criterion(preds, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # ---- Validation ----\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in val_loader:\n",
    "                preds = model(X)\n",
    "                loss = criterion(preds, y)\n",
    "                val_loss += loss.item()\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss={avg_train_loss:.4f}, Val Loss={avg_val_loss:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d1df242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     patient_id             datetime       Value  is_insulin  is_meal  \\\n",
      "0             1  1991-04-21 09:09:00   40.666667           1        0   \n",
      "1             1  1991-04-21 17:08:00   63.000000           1        0   \n",
      "2             1  1991-04-21 22:51:00  123.000000           0        0   \n",
      "3             1  1991-04-22 07:35:00   79.666667           1        0   \n",
      "4             1  1991-04-22 13:40:00    2.000000           1        0   \n",
      "..          ...                  ...         ...         ...      ...   \n",
      "505           1  1991-09-02 08:51:00   64.333333           1        0   \n",
      "506           1  1991-09-02 13:00:00    4.000000           1        0   \n",
      "507           1  1991-09-02 17:30:00   34.000000           1        0   \n",
      "508           1  1991-09-02 23:00:00  155.000000           0        0   \n",
      "509           1  1991-09-03 07:20:00   45.000000           1        0   \n",
      "\n",
      "     is_exercise     prev_bg  prev_insulin  prev_meal  prev_exercise  \\\n",
      "0              0         NaN           NaN        NaN            NaN   \n",
      "1              0   40.666667           1.0        0.0            0.0   \n",
      "2              0   63.000000           1.0        0.0            0.0   \n",
      "3              0  123.000000           0.0        0.0            0.0   \n",
      "4              0   79.666667           1.0        0.0            0.0   \n",
      "..           ...         ...           ...        ...            ...   \n",
      "505            0  174.000000           0.0        0.0            0.0   \n",
      "506            0   64.333333           1.0        0.0            0.0   \n",
      "507            0    4.000000           1.0        0.0            0.0   \n",
      "508            0   34.000000           1.0        0.0            0.0   \n",
      "509            0  155.000000           0.0        0.0            0.0   \n",
      "\n",
      "      target_bg  \n",
      "0     63.000000  \n",
      "1    123.000000  \n",
      "2     79.666667  \n",
      "3      2.000000  \n",
      "4    109.000000  \n",
      "..          ...  \n",
      "505    4.000000  \n",
      "506   34.000000  \n",
      "507  155.000000  \n",
      "508   45.000000  \n",
      "509         NaN  \n",
      "\n",
      "[510 rows x 11 columns]\n",
      "Epoch 1/120, Train Loss=7352.9430, Val Loss=5714.4720\n",
      "Epoch 2/120, Train Loss=7121.0093, Val Loss=5494.8895\n",
      "Epoch 3/120, Train Loss=6865.3472, Val Loss=5291.7017\n",
      "Epoch 4/120, Train Loss=6649.1028, Val Loss=5143.8402\n",
      "Epoch 5/120, Train Loss=6491.8089, Val Loss=5030.8951\n",
      "Epoch 6/120, Train Loss=6362.8659, Val Loss=4932.1023\n",
      "Epoch 7/120, Train Loss=6245.8581, Val Loss=4840.0550\n",
      "Epoch 8/120, Train Loss=6134.4621, Val Loss=4751.8981\n",
      "Epoch 9/120, Train Loss=6027.9829, Val Loss=4668.3825\n",
      "Epoch 10/120, Train Loss=5926.4860, Val Loss=4588.8497\n",
      "Epoch 11/120, Train Loss=5829.2244, Val Loss=4512.8008\n",
      "Epoch 12/120, Train Loss=5735.6962, Val Loss=4439.8407\n",
      "Epoch 13/120, Train Loss=5645.4700, Val Loss=4369.6637\n",
      "Epoch 14/120, Train Loss=5558.2405, Val Loss=4302.0495\n",
      "Epoch 15/120, Train Loss=5473.7785, Val Loss=4236.8254\n",
      "Epoch 16/120, Train Loss=5391.9034, Val Loss=4173.8518\n",
      "Epoch 17/120, Train Loss=5312.4681, Val Loss=4113.0133\n",
      "Epoch 18/120, Train Loss=5235.3511, Val Loss=4054.2118\n",
      "Epoch 19/120, Train Loss=5160.4483, Val Loss=3997.3633\n",
      "Epoch 20/120, Train Loss=5087.6704, Val Loss=3942.3927\n",
      "Epoch 21/120, Train Loss=5016.9387, Val Loss=3889.2324\n",
      "Epoch 22/120, Train Loss=4948.1823, Val Loss=3837.8227\n",
      "Epoch 23/120, Train Loss=4881.3379, Val Loss=3788.1082\n",
      "Epoch 24/120, Train Loss=4816.3474, Val Loss=3740.0378\n",
      "Epoch 25/120, Train Loss=4753.1570, Val Loss=3693.5637\n",
      "Epoch 26/120, Train Loss=4691.7172, Val Loss=3648.6408\n",
      "Epoch 27/120, Train Loss=4631.9811, Val Loss=3605.2275\n",
      "Epoch 28/120, Train Loss=4573.9053, Val Loss=3563.2830\n",
      "Epoch 29/120, Train Loss=4517.4477, Val Loss=3522.7694\n",
      "Epoch 30/120, Train Loss=4462.5688, Val Loss=3483.6492\n",
      "Epoch 31/120, Train Loss=4409.2307, Val Loss=3445.8875\n",
      "Epoch 32/120, Train Loss=4357.3968, Val Loss=3409.4496\n",
      "Epoch 33/120, Train Loss=4307.0323, Val Loss=3374.3027\n",
      "Epoch 34/120, Train Loss=4258.1029, Val Loss=3340.4148\n",
      "Epoch 35/120, Train Loss=4210.5764, Val Loss=3307.7541\n",
      "Epoch 36/120, Train Loss=4164.4204, Val Loss=3276.2905\n",
      "Epoch 37/120, Train Loss=4119.6040, Val Loss=3245.9941\n",
      "Epoch 38/120, Train Loss=4076.0970, Val Loss=3216.8360\n",
      "Epoch 39/120, Train Loss=4033.8701, Val Loss=3188.7878\n",
      "Epoch 40/120, Train Loss=3992.8940, Val Loss=3161.8213\n",
      "Epoch 41/120, Train Loss=3953.1409, Val Loss=3135.9095\n",
      "Epoch 42/120, Train Loss=3914.5831, Val Loss=3111.0250\n",
      "Epoch 43/120, Train Loss=3877.1932, Val Loss=3087.1421\n",
      "Epoch 44/120, Train Loss=3840.9450, Val Loss=3064.2347\n",
      "Epoch 45/120, Train Loss=3805.8122, Val Loss=3042.2773\n",
      "Epoch 46/120, Train Loss=3771.7691, Val Loss=3021.2453\n",
      "Epoch 47/120, Train Loss=3738.7907, Val Loss=3001.1139\n",
      "Epoch 48/120, Train Loss=3706.8521, Val Loss=2981.8586\n",
      "Epoch 49/120, Train Loss=3675.9290, Val Loss=2963.4559\n",
      "Epoch 50/120, Train Loss=3645.9972, Val Loss=2945.8822\n",
      "Epoch 51/120, Train Loss=3617.0333, Val Loss=2929.1149\n",
      "Epoch 52/120, Train Loss=3589.0138, Val Loss=2913.1306\n",
      "Epoch 53/120, Train Loss=3561.9160, Val Loss=2897.9075\n",
      "Epoch 54/120, Train Loss=3535.7174, Val Loss=2883.4230\n",
      "Epoch 55/120, Train Loss=3510.3958, Val Loss=2869.6562\n",
      "Epoch 56/120, Train Loss=3485.9292, Val Loss=2856.5853\n",
      "Epoch 57/120, Train Loss=3462.2960, Val Loss=2844.1894\n",
      "Epoch 58/120, Train Loss=3439.4753, Val Loss=2832.4476\n",
      "Epoch 59/120, Train Loss=3417.4460, Val Loss=2821.3401\n",
      "Epoch 60/120, Train Loss=3396.1878, Val Loss=2810.8463\n",
      "Epoch 61/120, Train Loss=3375.6800, Val Loss=2800.9475\n",
      "Epoch 62/120, Train Loss=3355.9032, Val Loss=2791.6230\n",
      "Epoch 63/120, Train Loss=3336.8375, Val Loss=2782.8547\n",
      "Epoch 64/120, Train Loss=3318.4636, Val Loss=2774.6238\n",
      "Epoch 65/120, Train Loss=3300.7626, Val Loss=2766.9119\n",
      "Epoch 66/120, Train Loss=3283.7157, Val Loss=2759.7008\n",
      "Epoch 67/120, Train Loss=3267.3049, Val Loss=2752.9732\n",
      "Epoch 68/120, Train Loss=3251.5117, Val Loss=2746.7114\n",
      "Epoch 69/120, Train Loss=3236.3187, Val Loss=2740.8984\n",
      "Epoch 70/120, Train Loss=3221.7081, Val Loss=2735.5174\n",
      "Epoch 71/120, Train Loss=3207.6632, Val Loss=2730.5522\n",
      "Epoch 72/120, Train Loss=3194.1667, Val Loss=2725.9865\n",
      "Epoch 73/120, Train Loss=3181.2025, Val Loss=2721.8051\n",
      "Epoch 74/120, Train Loss=3168.7540, Val Loss=2717.9917\n",
      "Epoch 75/120, Train Loss=3156.8056, Val Loss=2714.5319\n",
      "Epoch 76/120, Train Loss=3145.3414, Val Loss=2711.4107\n",
      "Epoch 77/120, Train Loss=3134.3466, Val Loss=2708.6140\n",
      "Epoch 78/120, Train Loss=3123.8057, Val Loss=2706.1273\n",
      "Epoch 79/120, Train Loss=3113.7043, Val Loss=2703.9368\n",
      "Epoch 80/120, Train Loss=3104.0278, Val Loss=2702.0294\n",
      "Epoch 81/120, Train Loss=3094.7622, Val Loss=2700.3920\n",
      "Epoch 82/120, Train Loss=3085.8938, Val Loss=2699.0113\n",
      "Epoch 83/120, Train Loss=3077.4089, Val Loss=2697.8754\n",
      "Epoch 84/120, Train Loss=3069.2946, Val Loss=2696.9717\n",
      "Epoch 85/120, Train Loss=3061.5378, Val Loss=2696.2888\n",
      "Epoch 86/120, Train Loss=3054.1260, Val Loss=2695.8151\n",
      "Epoch 87/120, Train Loss=3047.0470, Val Loss=2695.5391\n",
      "Epoch 88/120, Train Loss=3040.2885, Val Loss=2695.4504\n",
      "Epoch 89/120, Train Loss=3033.8392, Val Loss=2695.5382\n",
      "Epoch 90/120, Train Loss=3027.6873, Val Loss=2695.7926\n",
      "Epoch 91/120, Train Loss=3021.8218, Val Loss=2696.2030\n",
      "Epoch 92/120, Train Loss=3016.2321, Val Loss=2696.7606\n",
      "Epoch 93/120, Train Loss=3010.9075, Val Loss=2697.4556\n",
      "Epoch 94/120, Train Loss=3005.8378, Val Loss=2698.2794\n",
      "Epoch 95/120, Train Loss=3001.0126, Val Loss=2699.2229\n",
      "Epoch 96/120, Train Loss=2996.4230, Val Loss=2700.2778\n",
      "Epoch 97/120, Train Loss=2992.0587, Val Loss=2701.4363\n",
      "Epoch 98/120, Train Loss=2987.9111, Val Loss=2702.6903\n",
      "Epoch 99/120, Train Loss=2983.9712, Val Loss=2704.0326\n",
      "Epoch 100/120, Train Loss=2980.2303, Val Loss=2705.4556\n",
      "Epoch 101/120, Train Loss=2976.6801, Val Loss=2706.9527\n",
      "Epoch 102/120, Train Loss=2973.3125, Val Loss=2708.5170\n",
      "Epoch 103/120, Train Loss=2970.1196, Val Loss=2710.1424\n",
      "Epoch 104/120, Train Loss=2967.0937, Val Loss=2711.8221\n",
      "Epoch 105/120, Train Loss=2964.2278, Val Loss=2713.5510\n",
      "Epoch 106/120, Train Loss=2961.5146, Val Loss=2715.3231\n",
      "Epoch 107/120, Train Loss=2958.9471, Val Loss=2717.1331\n",
      "Epoch 108/120, Train Loss=2956.5190, Val Loss=2718.9759\n",
      "Epoch 109/120, Train Loss=2954.2235, Val Loss=2720.8468\n",
      "Epoch 110/120, Train Loss=2952.0546, Val Loss=2722.7407\n",
      "Epoch 111/120, Train Loss=2950.0066, Val Loss=2724.6537\n",
      "Epoch 112/120, Train Loss=2948.0734, Val Loss=2726.5811\n",
      "Epoch 113/120, Train Loss=2946.2499, Val Loss=2728.5198\n",
      "Epoch 114/120, Train Loss=2944.5302, Val Loss=2730.4649\n",
      "Epoch 115/120, Train Loss=2942.9097, Val Loss=2732.4138\n",
      "Epoch 116/120, Train Loss=2941.3833, Val Loss=2734.3630\n",
      "Epoch 117/120, Train Loss=2939.9463, Val Loss=2736.3088\n",
      "Epoch 118/120, Train Loss=2938.5943, Val Loss=2738.2488\n",
      "Epoch 119/120, Train Loss=2937.3227, Val Loss=2740.1804\n",
      "Epoch 120/120, Train Loss=2936.1276, Val Loss=2742.1003\n"
     ]
    }
   ],
   "source": [
    "# Select one patient (example: patient 1)\n",
    "# pdf = pdf.dropna(subset=[\"Value\", \"prev_bg\"])\n",
    "pdf = agg_df[agg_df[\"patient_id\"] == 1].sort_values(\"datetime\")\n",
    "print(pdf)\n",
    "# Train LSTM\n",
    "model = train_lstm(pdf, seq_len=10, epochs=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c80aa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def enrich_features(df):\n",
    "    df = df.copy()\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "    df = df.sort_values([\"patient_id\", \"datetime\"])\n",
    "    \n",
    "    # Base indicators\n",
    "    df[\"is_insulin\"] = df[\"Code\"].isin([33, 34, 35]).astype(int)\n",
    "    df[\"is_meal\"] = df[\"Code\"].isin([66, 67, 68, 72]).astype(int)\n",
    "    df[\"is_exercise\"] = df[\"Code\"].isin([69, 70, 71]).astype(int)\n",
    "    \n",
    "    # Insulin dose\n",
    "    df[\"insulin_dose\"] = np.where(df[\"is_insulin\"] == 1, df[\"Value\"], 0)\n",
    "\n",
    "    # Meal size mapping\n",
    "    meal_map = {66: 1, 67: 2, 68: -1, 72: 0}\n",
    "    df[\"meal_size\"] = df[\"Code\"].map(meal_map).fillna(0)\n",
    "\n",
    "    # Exercise level mapping\n",
    "    ex_map = {69: 1, 70: 2, 71: -1}\n",
    "    df[\"exercise_level\"] = df[\"Code\"].map(ex_map).fillna(0)\n",
    "\n",
    "    # Time since last reading per patient\n",
    "    df[\"time_since_last\"] = (\n",
    "        df.groupby(\"patient_id\")[\"datetime\"].diff().dt.total_seconds() / 60\n",
    "    ).fillna(0)\n",
    "\n",
    "    # Normalize BG per patient\n",
    "    df[\"Value_norm\"] = (\n",
    "        df.groupby(\"patient_id\")[\"Value\"].transform(lambda x: (x - x.mean()) / x.std(ddof=0))\n",
    "    )\n",
    "\n",
    "    # Fill any remaining NaNs\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = enrich_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "33247742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# 1. Create sequence dataset\n",
    "class BGDataset(Dataset):\n",
    "    def __init__(self, df, seq_len=5):\n",
    "        self.seq_len = seq_len\n",
    "        self.features = df[[\"Value\", \"is_insulin\", \"is_meal\", \"meal_size\", \"is_exercise\", \"exercise_level\", \"time_since_last\"]].values\n",
    "        self.targets = df[\"Value\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features) - self.seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.features[idx:idx+self.seq_len]\n",
    "        y = self.targets[idx+self.seq_len]\n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# 2. LSTM Model\n",
    "class BGLSTM(nn.Module):\n",
    "    def __init__(self, input_size=8, hidden_size=64, num_layers=2):\n",
    "        super(BGLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # last time step\n",
    "        return out.squeeze()\n",
    "\n",
    "# 3. Train function with validation\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_lstm(df, seq_len=5, epochs=200, lr=0.001, patience=50):\n",
    "    # ---- Chronological 80/20 split ----\n",
    "    train_size = int(0.8 * len(df))\n",
    "    train_df = df.iloc[:train_size]\n",
    "    val_df = df.iloc[train_size:]\n",
    "\n",
    "    train_loader = DataLoader(BGDataset(train_df, seq_len), batch_size=32, shuffle=False)\n",
    "    val_loader = DataLoader(BGDataset(val_df, seq_len), batch_size=32, shuffle=False)\n",
    "\n",
    "    model = BGLSTM(input_size=7)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_rmse = float(\"inf\")\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # ---- Training ----\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for X, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X)\n",
    "            loss = criterion(preds, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_rmse = np.sqrt(avg_train_loss)\n",
    "\n",
    "        # ---- Validation ----\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in val_loader:\n",
    "                preds = model(X)\n",
    "                loss = criterion(preds, y)\n",
    "                val_loss += loss.item()\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_rmse = np.sqrt(avg_val_loss)\n",
    "\n",
    "        # ---- Early Stopping ----\n",
    "        if val_rmse < best_val_rmse:\n",
    "            best_val_rmse = val_rmse\n",
    "            best_model_state = model.state_dict()\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"⏹️ Early stopping at epoch {epoch+1} (no improvement for {patience} epochs)\")\n",
    "            break\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train RMSE={train_rmse:.4f}, Val RMSE={val_rmse:.4f}\")\n",
    "\n",
    "    # Restore best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    print(f\"Best Val RMSE: {best_val_rmse:.4f}\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c8230da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date   Time  Code  Value  patient_id             datetime  \\\n",
      "0    04-21-1991   9:09    58  100.0           1  1991-04-21 09:09:00   \n",
      "1    04-21-1991   9:09    33    9.0           1  1991-04-21 09:09:00   \n",
      "2    04-21-1991   9:09    34   13.0           1  1991-04-21 09:09:00   \n",
      "3    04-21-1991  17:08    62  119.0           1  1991-04-21 17:08:00   \n",
      "4    04-21-1991  17:08    33    7.0           1  1991-04-21 17:08:00   \n",
      "..          ...    ...   ...    ...         ...                  ...   \n",
      "937  09-02-1991  17:30    62   61.0           1  1991-09-02 17:30:00   \n",
      "939  09-02-1991  23:00    48  155.0           1  1991-09-02 23:00:00   \n",
      "941  09-03-1991   7:20    33    9.0           1  1991-09-03 07:20:00   \n",
      "940  09-03-1991   7:20    58  110.0           1  1991-09-03 07:20:00   \n",
      "942  09-03-1991   7:20    34   16.0           1  1991-09-03 07:20:00   \n",
      "\n",
      "    record_type  is_insulin  is_meal  is_exercise  insulin_dose  meal_size  \\\n",
      "0    Electronic           0        0            0           0.0        0.0   \n",
      "1    Electronic           1        0            0           9.0        0.0   \n",
      "2    Electronic           1        0            0          13.0        0.0   \n",
      "3    Electronic           0        0            0           0.0        0.0   \n",
      "4    Electronic           1        0            0           7.0        0.0   \n",
      "..          ...         ...      ...          ...           ...        ...   \n",
      "937  Electronic           0        0            0           0.0        0.0   \n",
      "939  Electronic           0        0            0           0.0        0.0   \n",
      "941  Electronic           1        0            0           9.0        0.0   \n",
      "940  Electronic           0        0            0           0.0        0.0   \n",
      "942  Electronic           1        0            0          16.0        0.0   \n",
      "\n",
      "     exercise_level  time_since_last  Value_norm  \n",
      "0               0.0              0.0    0.380845  \n",
      "1               0.0              0.0   -0.682589  \n",
      "2               0.0              0.0   -0.635844  \n",
      "3               0.0            479.0    0.602881  \n",
      "4               0.0              0.0   -0.705961  \n",
      "..              ...              ...         ...  \n",
      "937             0.0            270.0   -0.074912  \n",
      "939             0.0            330.0    1.023580  \n",
      "941             0.0              0.0   -0.682589  \n",
      "940             0.0            500.0    0.497706  \n",
      "942             0.0              0.0   -0.600786  \n",
      "\n",
      "[943 rows x 15 columns]\n",
      "Epoch 1/200, Train RMSE=108.4140, Val RMSE=108.4305\n",
      "Epoch 2/200, Train RMSE=106.1088, Val RMSE=106.7166\n",
      "Epoch 3/200, Train RMSE=104.6568, Val RMSE=105.6287\n",
      "Epoch 4/200, Train RMSE=103.5694, Val RMSE=104.6899\n",
      "Epoch 5/200, Train RMSE=102.5902, Val RMSE=103.8255\n",
      "Epoch 6/200, Train RMSE=101.6773, Val RMSE=103.0155\n",
      "Epoch 7/200, Train RMSE=100.8150, Val RMSE=102.2493\n",
      "Epoch 8/200, Train RMSE=99.9950, Val RMSE=101.5213\n",
      "Epoch 9/200, Train RMSE=99.2121, Val RMSE=100.8276\n",
      "Epoch 10/200, Train RMSE=98.4632, Val RMSE=100.1655\n",
      "Epoch 11/200, Train RMSE=97.7458, Val RMSE=99.5333\n",
      "Epoch 12/200, Train RMSE=97.0583, Val RMSE=98.9292\n",
      "Epoch 13/200, Train RMSE=96.3993, Val RMSE=98.3525\n",
      "Epoch 14/200, Train RMSE=95.7679, Val RMSE=97.8019\n",
      "Epoch 15/200, Train RMSE=95.1631, Val RMSE=97.2765\n",
      "Epoch 16/200, Train RMSE=94.5838, Val RMSE=96.7755\n",
      "Epoch 17/200, Train RMSE=94.0295, Val RMSE=96.2981\n",
      "Epoch 18/200, Train RMSE=93.4994, Val RMSE=95.8436\n",
      "Epoch 19/200, Train RMSE=92.9927, Val RMSE=95.4112\n",
      "Epoch 20/200, Train RMSE=92.5088, Val RMSE=95.0004\n",
      "Epoch 21/200, Train RMSE=92.0472, Val RMSE=94.6104\n",
      "Epoch 22/200, Train RMSE=91.6071, Val RMSE=94.2406\n",
      "Epoch 23/200, Train RMSE=91.1879, Val RMSE=93.8903\n",
      "Epoch 24/200, Train RMSE=90.7890, Val RMSE=93.5589\n",
      "Epoch 25/200, Train RMSE=90.4099, Val RMSE=93.2457\n",
      "Epoch 26/200, Train RMSE=90.0498, Val RMSE=92.9502\n",
      "Epoch 27/200, Train RMSE=89.7082, Val RMSE=92.6717\n",
      "Epoch 28/200, Train RMSE=89.3845, Val RMSE=92.4095\n",
      "Epoch 29/200, Train RMSE=89.0781, Val RMSE=92.1632\n",
      "Epoch 30/200, Train RMSE=88.7883, Val RMSE=91.9319\n",
      "Epoch 31/200, Train RMSE=88.5146, Val RMSE=91.7153\n",
      "Epoch 32/200, Train RMSE=88.2565, Val RMSE=91.5125\n",
      "Epoch 33/200, Train RMSE=88.0132, Val RMSE=91.3231\n",
      "Epoch 34/200, Train RMSE=87.7842, Val RMSE=91.1465\n",
      "Epoch 35/200, Train RMSE=87.5689, Val RMSE=90.9820\n",
      "Epoch 36/200, Train RMSE=87.3668, Val RMSE=90.8292\n",
      "Epoch 37/200, Train RMSE=87.1773, Val RMSE=90.6874\n",
      "Epoch 38/200, Train RMSE=86.9999, Val RMSE=90.5561\n",
      "Epoch 39/200, Train RMSE=86.8339, Val RMSE=90.4348\n",
      "Epoch 40/200, Train RMSE=86.6788, Val RMSE=90.3229\n",
      "Epoch 41/200, Train RMSE=86.5342, Val RMSE=90.2200\n",
      "Epoch 42/200, Train RMSE=86.3994, Val RMSE=90.1254\n",
      "Epoch 43/200, Train RMSE=86.2740, Val RMSE=90.0388\n",
      "Epoch 44/200, Train RMSE=86.1576, Val RMSE=89.9597\n",
      "Epoch 45/200, Train RMSE=86.0495, Val RMSE=89.8876\n",
      "Epoch 46/200, Train RMSE=85.9494, Val RMSE=89.8221\n",
      "Epoch 47/200, Train RMSE=85.8567, Val RMSE=89.7627\n",
      "Epoch 48/200, Train RMSE=85.7712, Val RMSE=89.7090\n",
      "Epoch 49/200, Train RMSE=85.6922, Val RMSE=89.6607\n",
      "Epoch 50/200, Train RMSE=85.6195, Val RMSE=89.6173\n",
      "Epoch 51/200, Train RMSE=85.5527, Val RMSE=89.5786\n",
      "Epoch 52/200, Train RMSE=85.4912, Val RMSE=89.5441\n",
      "Epoch 53/200, Train RMSE=85.4349, Val RMSE=89.5135\n",
      "Epoch 54/200, Train RMSE=85.3834, Val RMSE=89.4866\n",
      "Epoch 55/200, Train RMSE=85.3362, Val RMSE=89.4630\n",
      "Epoch 56/200, Train RMSE=85.2932, Val RMSE=89.4424\n",
      "Epoch 57/200, Train RMSE=85.2540, Val RMSE=89.4246\n",
      "Epoch 58/200, Train RMSE=85.2183, Val RMSE=89.4093\n",
      "Epoch 59/200, Train RMSE=85.1859, Val RMSE=89.3963\n",
      "Epoch 60/200, Train RMSE=85.1565, Val RMSE=89.3855\n",
      "Epoch 61/200, Train RMSE=85.1299, Val RMSE=89.3764\n",
      "Epoch 62/200, Train RMSE=85.1058, Val RMSE=89.3691\n",
      "Epoch 63/200, Train RMSE=85.0841, Val RMSE=89.3632\n",
      "Epoch 64/200, Train RMSE=85.0646, Val RMSE=89.3587\n",
      "Epoch 65/200, Train RMSE=85.0470, Val RMSE=89.3554\n",
      "Epoch 66/200, Train RMSE=85.0312, Val RMSE=89.3532\n",
      "Epoch 67/200, Train RMSE=85.0170, Val RMSE=89.3518\n",
      "Epoch 68/200, Train RMSE=85.0044, Val RMSE=89.3513\n",
      "Epoch 69/200, Train RMSE=84.9931, Val RMSE=89.3514\n",
      "Epoch 70/200, Train RMSE=84.9830, Val RMSE=89.3522\n",
      "Epoch 71/200, Train RMSE=84.9740, Val RMSE=89.3534\n",
      "Epoch 72/200, Train RMSE=84.9660, Val RMSE=89.3551\n",
      "Epoch 73/200, Train RMSE=84.9589, Val RMSE=89.3571\n",
      "Epoch 74/200, Train RMSE=84.9527, Val RMSE=89.3594\n",
      "Epoch 75/200, Train RMSE=84.9471, Val RMSE=89.3619\n",
      "Epoch 76/200, Train RMSE=84.9423, Val RMSE=89.3646\n",
      "Epoch 77/200, Train RMSE=84.9380, Val RMSE=89.3674\n",
      "Epoch 78/200, Train RMSE=84.9342, Val RMSE=89.3703\n",
      "Epoch 79/200, Train RMSE=84.9309, Val RMSE=89.3733\n",
      "Epoch 80/200, Train RMSE=84.9280, Val RMSE=89.3763\n",
      "Epoch 81/200, Train RMSE=84.9254, Val RMSE=89.3792\n",
      "Epoch 82/200, Train RMSE=84.9232, Val RMSE=89.3822\n",
      "Epoch 83/200, Train RMSE=84.9213, Val RMSE=89.3851\n",
      "Epoch 84/200, Train RMSE=84.9196, Val RMSE=89.3879\n",
      "Epoch 85/200, Train RMSE=84.9182, Val RMSE=89.3907\n",
      "Epoch 86/200, Train RMSE=84.9169, Val RMSE=89.3934\n",
      "Epoch 87/200, Train RMSE=84.9158, Val RMSE=89.3960\n",
      "Epoch 88/200, Train RMSE=84.9149, Val RMSE=89.3984\n",
      "Epoch 89/200, Train RMSE=84.9141, Val RMSE=89.4008\n",
      "Epoch 90/200, Train RMSE=84.9134, Val RMSE=89.4031\n",
      "Epoch 91/200, Train RMSE=84.9128, Val RMSE=89.4052\n",
      "Epoch 92/200, Train RMSE=84.9123, Val RMSE=89.4073\n",
      "Epoch 93/200, Train RMSE=84.9119, Val RMSE=89.4092\n",
      "Epoch 94/200, Train RMSE=84.9115, Val RMSE=89.4110\n",
      "Epoch 95/200, Train RMSE=84.9112, Val RMSE=89.4127\n",
      "Epoch 96/200, Train RMSE=84.9109, Val RMSE=89.4142\n",
      "Epoch 97/200, Train RMSE=84.9106, Val RMSE=89.4157\n",
      "Epoch 98/200, Train RMSE=84.9104, Val RMSE=89.4171\n",
      "Epoch 99/200, Train RMSE=84.9102, Val RMSE=89.4183\n",
      "Epoch 100/200, Train RMSE=84.9100, Val RMSE=89.4195\n",
      "Epoch 101/200, Train RMSE=84.9095, Val RMSE=89.4198\n",
      "Epoch 102/200, Train RMSE=84.8846, Val RMSE=89.3282\n",
      "Epoch 103/200, Train RMSE=84.8118, Val RMSE=89.2291\n",
      "Epoch 104/200, Train RMSE=84.7015, Val RMSE=89.1061\n",
      "Epoch 105/200, Train RMSE=84.4641, Val RMSE=88.6812\n",
      "Epoch 106/200, Train RMSE=83.5098, Val RMSE=87.0177\n",
      "Epoch 107/200, Train RMSE=82.4211, Val RMSE=86.1576\n",
      "Epoch 108/200, Train RMSE=81.5734, Val RMSE=85.9759\n",
      "Epoch 109/200, Train RMSE=80.8463, Val RMSE=85.1159\n",
      "Epoch 110/200, Train RMSE=80.0194, Val RMSE=84.7065\n",
      "Epoch 111/200, Train RMSE=79.4836, Val RMSE=84.5703\n",
      "Epoch 112/200, Train RMSE=79.0711, Val RMSE=84.0637\n",
      "Epoch 113/200, Train RMSE=78.2169, Val RMSE=84.0931\n",
      "Epoch 114/200, Train RMSE=77.8221, Val RMSE=83.5392\n",
      "Epoch 115/200, Train RMSE=77.6512, Val RMSE=83.7362\n",
      "Epoch 116/200, Train RMSE=77.0277, Val RMSE=83.6463\n",
      "Epoch 117/200, Train RMSE=76.5884, Val RMSE=83.2814\n",
      "Epoch 118/200, Train RMSE=76.0310, Val RMSE=83.5187\n",
      "Epoch 119/200, Train RMSE=75.7002, Val RMSE=83.2701\n",
      "Epoch 120/200, Train RMSE=75.2310, Val RMSE=83.0134\n",
      "Epoch 121/200, Train RMSE=74.8101, Val RMSE=82.3259\n",
      "Epoch 122/200, Train RMSE=74.3683, Val RMSE=82.4550\n",
      "Epoch 123/200, Train RMSE=73.8288, Val RMSE=82.6004\n",
      "Epoch 124/200, Train RMSE=73.4405, Val RMSE=82.3690\n",
      "Epoch 125/200, Train RMSE=72.9703, Val RMSE=82.4263\n",
      "Epoch 126/200, Train RMSE=72.5217, Val RMSE=82.6221\n",
      "Epoch 127/200, Train RMSE=72.1501, Val RMSE=82.4674\n",
      "Epoch 128/200, Train RMSE=71.6381, Val RMSE=82.2753\n",
      "Epoch 129/200, Train RMSE=71.3722, Val RMSE=82.3685\n",
      "Epoch 130/200, Train RMSE=70.8846, Val RMSE=82.2365\n",
      "Epoch 131/200, Train RMSE=71.1246, Val RMSE=82.0277\n",
      "Epoch 132/200, Train RMSE=70.8605, Val RMSE=81.5694\n",
      "Epoch 133/200, Train RMSE=70.5929, Val RMSE=82.3249\n",
      "Epoch 134/200, Train RMSE=70.3563, Val RMSE=82.0086\n",
      "Epoch 135/200, Train RMSE=69.9194, Val RMSE=81.2984\n",
      "Epoch 136/200, Train RMSE=69.1921, Val RMSE=81.1894\n",
      "Epoch 137/200, Train RMSE=68.3992, Val RMSE=81.5708\n",
      "Epoch 138/200, Train RMSE=67.9713, Val RMSE=81.4277\n",
      "Epoch 139/200, Train RMSE=67.6582, Val RMSE=81.4969\n",
      "Epoch 140/200, Train RMSE=67.0979, Val RMSE=81.3299\n",
      "Epoch 141/200, Train RMSE=66.8199, Val RMSE=81.3628\n",
      "Epoch 142/200, Train RMSE=66.1674, Val RMSE=81.2139\n",
      "Epoch 143/200, Train RMSE=65.8603, Val RMSE=81.4798\n",
      "Epoch 144/200, Train RMSE=65.5553, Val RMSE=81.3246\n",
      "Epoch 145/200, Train RMSE=65.1490, Val RMSE=81.5572\n",
      "Epoch 146/200, Train RMSE=64.9431, Val RMSE=81.2053\n",
      "Epoch 147/200, Train RMSE=64.8399, Val RMSE=81.0763\n",
      "Epoch 148/200, Train RMSE=64.2653, Val RMSE=80.4774\n",
      "Epoch 149/200, Train RMSE=63.6209, Val RMSE=80.7111\n",
      "Epoch 150/200, Train RMSE=63.4747, Val RMSE=80.3241\n",
      "Epoch 151/200, Train RMSE=63.0040, Val RMSE=79.8538\n",
      "Epoch 152/200, Train RMSE=62.4818, Val RMSE=79.8767\n",
      "Epoch 153/200, Train RMSE=61.7439, Val RMSE=79.7118\n",
      "Epoch 154/200, Train RMSE=61.7130, Val RMSE=78.5863\n",
      "Epoch 155/200, Train RMSE=61.5267, Val RMSE=79.9042\n",
      "Epoch 156/200, Train RMSE=61.7471, Val RMSE=78.9596\n",
      "Epoch 157/200, Train RMSE=61.9465, Val RMSE=80.7986\n",
      "Epoch 158/200, Train RMSE=62.4420, Val RMSE=80.9135\n",
      "Epoch 159/200, Train RMSE=63.0122, Val RMSE=81.6171\n",
      "Epoch 160/200, Train RMSE=63.3014, Val RMSE=84.0358\n",
      "Epoch 161/200, Train RMSE=61.9315, Val RMSE=83.5499\n",
      "Epoch 162/200, Train RMSE=59.7558, Val RMSE=84.5415\n",
      "Epoch 163/200, Train RMSE=58.6605, Val RMSE=82.8550\n",
      "Epoch 164/200, Train RMSE=57.7919, Val RMSE=83.1743\n",
      "Epoch 165/200, Train RMSE=57.1444, Val RMSE=83.1742\n",
      "Epoch 166/200, Train RMSE=56.5086, Val RMSE=82.9124\n",
      "Epoch 167/200, Train RMSE=56.0511, Val RMSE=82.8270\n",
      "Epoch 168/200, Train RMSE=55.6302, Val RMSE=82.8774\n",
      "Epoch 169/200, Train RMSE=55.0286, Val RMSE=83.2972\n",
      "Epoch 170/200, Train RMSE=54.6857, Val RMSE=83.4128\n",
      "Epoch 171/200, Train RMSE=53.9738, Val RMSE=84.5220\n",
      "Epoch 172/200, Train RMSE=53.5795, Val RMSE=83.3767\n",
      "Epoch 173/200, Train RMSE=52.9322, Val RMSE=84.1712\n",
      "Epoch 174/200, Train RMSE=52.5097, Val RMSE=84.1401\n",
      "Epoch 175/200, Train RMSE=51.9902, Val RMSE=83.6315\n",
      "Epoch 176/200, Train RMSE=51.6255, Val RMSE=84.8359\n",
      "Epoch 177/200, Train RMSE=51.2497, Val RMSE=84.3606\n",
      "Epoch 178/200, Train RMSE=50.8802, Val RMSE=84.9898\n",
      "Epoch 179/200, Train RMSE=50.8412, Val RMSE=85.8799\n",
      "Epoch 180/200, Train RMSE=50.4576, Val RMSE=84.4511\n",
      "Epoch 181/200, Train RMSE=50.1223, Val RMSE=85.3359\n",
      "Epoch 182/200, Train RMSE=49.4050, Val RMSE=86.2276\n",
      "Epoch 183/200, Train RMSE=48.9453, Val RMSE=85.3589\n",
      "Epoch 184/200, Train RMSE=49.0019, Val RMSE=86.2316\n",
      "Epoch 185/200, Train RMSE=49.1969, Val RMSE=87.1187\n",
      "Epoch 186/200, Train RMSE=49.1130, Val RMSE=87.1350\n",
      "Epoch 187/200, Train RMSE=49.2040, Val RMSE=86.5888\n",
      "Epoch 188/200, Train RMSE=48.5643, Val RMSE=88.4376\n",
      "Epoch 189/200, Train RMSE=48.2810, Val RMSE=86.7249\n",
      "Epoch 190/200, Train RMSE=48.2805, Val RMSE=89.9651\n",
      "Epoch 191/200, Train RMSE=48.8224, Val RMSE=88.7297\n",
      "Epoch 192/200, Train RMSE=48.3793, Val RMSE=88.2024\n",
      "Epoch 193/200, Train RMSE=48.3087, Val RMSE=88.6660\n",
      "Epoch 194/200, Train RMSE=47.4894, Val RMSE=89.1692\n",
      "Epoch 195/200, Train RMSE=47.1797, Val RMSE=90.0765\n",
      "Epoch 196/200, Train RMSE=47.5043, Val RMSE=93.4671\n",
      "Epoch 197/200, Train RMSE=49.8161, Val RMSE=91.2271\n",
      "Epoch 198/200, Train RMSE=49.5112, Val RMSE=91.0843\n",
      "Epoch 199/200, Train RMSE=51.4858, Val RMSE=88.8600\n",
      "Epoch 200/200, Train RMSE=53.3155, Val RMSE=86.2970\n",
      "Best Val RMSE: 78.5863\n"
     ]
    }
   ],
   "source": [
    "# Select one patient (example: patient 1)\n",
    "# pdf = pdf.dropna(subset=[\"Value\", \"prev_bg\"])\n",
    "pdf = df[df[\"patient_id\"] == 1].sort_values(\"datetime\")\n",
    "print(pdf)\n",
    "# Train LSTM\n",
    "model = train_lstm(pdf, seq_len=10, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc83a8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tcn(df, seq_len=10, epochs=500, lr=0.001, patience=20, min_delta=1e-4):\n",
    "    dataset = BGDataset(df, seq_len)\n",
    "    n = len(dataset)\n",
    "    if n < 50:\n",
    "        raise ValueError(\"Dataset too small for training\")\n",
    "\n",
    "    train_size = int(0.8 * n)\n",
    "    val_size = n - train_size\n",
    "\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = TCNModel()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for X, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X)\n",
    "            loss = criterion(preds, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in val_loader:\n",
    "                preds = model(X)\n",
    "                val_loss += criterion(preds, y).item()\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        # Early Stopping logic\n",
    "        if best_val_loss - val_loss > min_delta:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss={total_loss/len(train_loader):.4f}, Val Loss={val_loss:.4f}\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch+1} epochs. Best Val Loss={best_val_loss:.4f}\")\n",
    "            break\n",
    "\n",
    "    # Restore best model weights\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    # --- Compute true RMSE in mg/dL ---\n",
    "    bg_std = df[\"Value\"].std()  # standard deviation in mg/dL\n",
    "    val_rmse_mgdl = (best_val_loss ** 0.5) * bg_std\n",
    "    print(f\"\\nFinal Validation RMSE ≈ {val_rmse_mgdl:.2f} mg/dL\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f9da9b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500, Train Loss=3937.5957, Val Loss=50.2669\n",
      "Epoch 2/500, Train Loss=135.2427, Val Loss=6.5182\n",
      "Epoch 3/500, Train Loss=109.5938, Val Loss=2.6934\n",
      "Epoch 4/500, Train Loss=50.4568, Val Loss=1.2888\n",
      "Epoch 5/500, Train Loss=31.2680, Val Loss=4.8166\n",
      "Epoch 6/500, Train Loss=5.1114, Val Loss=1.0759\n",
      "Epoch 7/500, Train Loss=5.9161, Val Loss=0.9990\n",
      "Epoch 8/500, Train Loss=5.0175, Val Loss=1.0171\n",
      "Epoch 9/500, Train Loss=11.6311, Val Loss=0.9906\n",
      "Epoch 10/500, Train Loss=2.2615, Val Loss=0.9953\n",
      "Epoch 11/500, Train Loss=1.6084, Val Loss=0.9752\n",
      "Epoch 12/500, Train Loss=1.3699, Val Loss=1.0297\n",
      "Epoch 13/500, Train Loss=1.1331, Val Loss=0.9846\n",
      "Epoch 14/500, Train Loss=1.2915, Val Loss=0.9965\n",
      "Epoch 15/500, Train Loss=1.5798, Val Loss=0.9959\n",
      "Epoch 16/500, Train Loss=4.0096, Val Loss=0.9956\n",
      "Epoch 17/500, Train Loss=15.7582, Val Loss=0.9960\n",
      "Epoch 18/500, Train Loss=1.4457, Val Loss=0.9956\n",
      "Epoch 19/500, Train Loss=1.1049, Val Loss=0.9956\n",
      "Epoch 20/500, Train Loss=1.0097, Val Loss=0.9956\n",
      "Epoch 21/500, Train Loss=1.1385, Val Loss=0.9957\n",
      "Epoch 22/500, Train Loss=1.0240, Val Loss=0.9956\n",
      "Epoch 23/500, Train Loss=0.9995, Val Loss=0.9957\n",
      "Epoch 24/500, Train Loss=1.0001, Val Loss=0.9959\n",
      "Epoch 25/500, Train Loss=0.9995, Val Loss=0.9956\n",
      "Epoch 26/500, Train Loss=1.0797, Val Loss=0.9956\n",
      "Epoch 27/500, Train Loss=1.3796, Val Loss=0.9957\n",
      "Epoch 28/500, Train Loss=0.9997, Val Loss=0.9956\n",
      "Epoch 29/500, Train Loss=1.0041, Val Loss=0.9958\n",
      "Epoch 30/500, Train Loss=0.9995, Val Loss=0.9956\n",
      "Epoch 31/500, Train Loss=0.9997, Val Loss=0.9956\n",
      "\n",
      "Early stopping triggered after 31 epochs. Best Val Loss=0.9752\n",
      "\n",
      "Final Validation RMSE ≈ 92.31 mg/dL\n"
     ]
    }
   ],
   "source": [
    "pdf = df[df[\"patient_id\"] == 1].sort_values(\"datetime\")\n",
    "model = train_tcn(df, seq_len=20, epochs=500, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d2ba45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
